{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. O problema\n",
    "\n",
    "O diretor de um banco está descontente com o fluxo de clientes abandonando os serviços do banco, notadamente o de cartão de crédito. Ele ficaria feliz se alguém conseguisse prever os próximos que abandonarão os serviços para que o banco possa agir proativamente, oferecedendo serviços melhores e modificando a decisão dos clientes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 O exercício\n",
    "\n",
    "O exercício consiste em \n",
    "\n",
    "(i) elaborar uma breve análise exploratória de dados com o objetivo de identificar o comportamento das variáveis e analisar que atributos se conectam com a ação de cancelamento dos cartões de crédito dos clientes. Em seguida, será realizado um \n",
    "\n",
    "(ii) pré-processamento dos dados, mas não a modelagem, pois está será abordada mais à frente no programa de estudos."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 O Data Set\n",
    "\n",
    "O dataset contém pouco mais de 10000 linhas, sendo cada uma um cliente, com os seguintes atributos:\n",
    "\n",
    "- \"CLIENTNUM\": código de identificação do cliente;\n",
    "- \"Attrition_Flag\": indica se houve cancelamento ou se a pessoa ainda é cliente;\n",
    "- \"Customer_Age\": idade do cliente ou ex-cliente;\n",
    "- \"Gender\": gênero;\n",
    "- \"Dependent_count\": quantidade de dependentes;\n",
    "- \"Education_Level\": nível de escolaridade;\n",
    "- \"Marital_Status\": estado civil;\n",
    "- \"Income_Category\": renda anual categorizada;\n",
    "- \"Card_Category\": qual cartão o cliente possui (blue, silver, outros )\n",
    "- \"Months_on_book\": tempo como cliente em meses;\n",
    "- \"Total_Relationship_Count\": quantos produtos o cliente contratou com o banco;\n",
    "- \"Months_Inactive_12_mon\": meses em que o cliente esteve inativo no último ano;\n",
    "- \"Contacts_Count_12_mon\": número de contatos nos últimos 12 meses\";\n",
    "- \"Credit_Limit\": limite de crédito total;\n",
    "- \"Total_Revolving_Bal\": limite de crédito consumido;\n",
    "- \"Total_Amt_Chng_Q4_Q1\": mudança de quantidade de valores transacionais  entre o quarto trimestre de um ano e o primeiro de outro.\n",
    "- \"Avg_Open_To_Buy\": limite de crédito disponível;\n",
    "- \"Total_Trans_Amt\": valor total utilizado em transferências;\n",
    "- \"Total_Trans_Ct\": quantidade total de transferências;\n",
    "- \"Total_Ct_Chng_Q4_Q1\": mudança de quantidade de transações entre o quarto trimestre de um ano e o primeiro de outro.\n",
    "- \"Avg_Utilization_Ratio\": taxa de utilização do cartão.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Abordagem\n",
    "\n",
    "Se trata de um problema de _churn_, em que o _business_ deseja saber em quais clientes devem dedicar seus esforços de maneira a mudar suas possíveis futuras decisões de abandonar os serviços do banco.\n",
    "\n",
    "Nesse sentido, após uma olhada inicial e uma limpeza geral no dataset, buscaremos inferir quais as principais variáveis parecem indicar a virada de chave para um cliente se tornar ex-cliente.\n",
    "\n",
    "Para isso, separeremos o dataset em dois: um de clientes existentes e outro de ex-clientes. Apesar do desequilíbrio entre a quantidade de dados de clientes versus a quantidade de dados de ex-clientes, como se verá, acredita-se que isolando os dados dos ex-clientes poderemos averiguar quais os principais atributos prevalecem nessa categoria _que não prevalecem nos atuais clientes_.\n",
    "\n",
    "Espera-se que, dessa maneira, a análise possa produzir insights para eventuais ações que o diretor deseja tomar em relação aos atuais clientes que possam vir a declinar os serviços do banco."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Lendo os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os #pacote para interação com o sistema operacional\n",
    "import pandas as pd #biblioteca pandas para interação e manipulação de dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['charts', 'notebook_final.ipynb', 'raw_data', 'README.md']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Verificando os arquivos presentes no diretório\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bank_churn.csv'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tudo mais constante, facilitando a leitura do dataset pelo pandas\n",
    "raw_dataset_folder = os.listdir(\"raw_data\")\n",
    "dataset = raw_dataset_folder[0]\n",
    "dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Terminando o carregamento dos dados em uma variável, podemos utilizar a biblioteca `pandas` para transformar esses dados em um formato `DataFrame` facilmente lido pelo python. Para uma intuição inicial, vamos visualizar o dataset no formato tabular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'bank_churn.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_raw \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(dataset)\n\u001b[0;32m      2\u001b[0m df_raw\u001b[39m.\u001b[39mhead()\n",
      "File \u001b[1;32me:\\Analytics\\caderno\\venv\\Lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32me:\\Analytics\\caderno\\venv\\Lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32me:\\Analytics\\caderno\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32me:\\Analytics\\caderno\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32me:\\Analytics\\caderno\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32me:\\Analytics\\caderno\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1733\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m   1734\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1735\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1736\u001b[0m     f,\n\u001b[0;32m   1737\u001b[0m     mode,\n\u001b[0;32m   1738\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1739\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1740\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1741\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1742\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1743\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1744\u001b[0m )\n\u001b[0;32m   1745\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32me:\\Analytics\\caderno\\venv\\Lib\\site-packages\\pandas\\io\\common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    852\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    853\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    855\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 856\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    857\u001b[0m             handle,\n\u001b[0;32m    858\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    859\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    860\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    861\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    862\u001b[0m         )\n\u001b[0;32m    863\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    865\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'bank_churn.csv'"
     ]
    }
   ],
   "source": [
    "df_raw = pd.read_csv(dataset)\n",
    "df_raw.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na primeira visão do dataset, vemos que a coluna Clientnum é virtualmente inútil para nosso exercício, pois ela apresenta um valor conhecido como chave primária de usuário. Isso significa que cada usuário possui uma e apenas uma chave referente ao seu cadastro, e elas não se repetem. Não apresentando padrão específico e não nos interessando a identificação dos clientes, podemos excluí-la sem correr risco de perda de informação relevante. Em seguida, verificaremos os tipos de dados em cada coluna e se há elementos faltantes que exijam algum tipo de limpeza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excluindo a coluna clientnum\n",
    "\n",
    "df = df_raw.drop(columns=[\"CLIENTNUM\"]).copy()\n",
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algumas colunas são numéricas, e outras são objetos. Vendo acima a exibição do dataframe, são as colunas que apresentam dados categorizados, como o nível salarial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Não há dados nulos\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dada a inexistência de nulos, verificamos a existência de duplicatas. Como explicamos anteriormente, cada cliente tem apenas um conjunto de valores associados a ele. Portanto, linhas duplicadas não acrescentam informação relevante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().any()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Garantindo os dois passos anteriores, podemos seguir com a estratégia de análise dos dados apresentados."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Análise Exploratória de Dados"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apesar de existirem diversas formas de tentar entender o motivo do _churn_ pelos clientes por meio do processo de modelagem com _machine learning_, o processo de análise exploratória nos permite criar intuições que podem se confirmar ou não no processo de modelagem. Esse processo é extremamente útil para a construção de hipóteses validadas posteriormente. Em muitos casos, uma simples heurística pode se mostrar eficiente e bem menos custosa do que desenvolver um modelo de aprendizado de máquina.\n",
    "\n",
    "Inicialmente, visualizaremos as principais estatísticas descritivas do dataframe, utilizando o método `describe`, que também nos ajudará a ter uma intuição de quais variáveis são numéricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T.style.bar(\n",
    "    subset=['mean'],\n",
    "    color='lightsalmon').background_gradient(\n",
    "    subset=['std'], cmap='plasma').background_gradient(\n",
    "    subset=['75%'], cmap='plasma').background_gradient(\n",
    "    subset=['max'], cmap='plasma')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que não são todas as colunas que apresentam valores numéricos não-categóricos. Essas colunas podem ser facilmente visualizadas através de um histograma de frequências. Nos atentaremos também ao fato de que algumas variáveis numéricas podem representar valores discretos e talvez sejam melhor visualizadas em um gráfico de pizza ou de barras."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para nosso desenvolvimento, separaremos os conjuntos pela variável-objetivo, `Attrition_Flag`, e desenvolveremos diversas visualizações para tentar entender de maneira qualitativa quais atributos podem indicar quando um cliente está para se tornar ex-cliente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando os dataframes\n",
    "\n",
    "existing = df[df[\"Attrition_Flag\"] == \"Existing Customer\"].copy()\n",
    "attrited = df[df[\"Attrition_Flag\"] == \"Attrited Customer\"].copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Avaliação por histogramas. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo, utilizaremos um laço de repetição para gerar visualizações por força bruta. Nosso intuito é o de facilitar a visualização das medianas e a distribuição das variáveis pelos atributos, que são numerosos, evitando tarefa repetitiva sem necessidade. Algumas visualizações falharão em razão da natureza categórica do atributo, que geralmente armazera objetos não-numéricos como dados. Estes casos, assim como os cuja visualização não ficarem adequadas por meio do histograma, serão comentados mais adiante. A mediana será utilizada como estatística descritiva padrão para impedir que outliers impactem a análise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importando o matplotlib\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos fazer uma tentativa de visualização por força bruta\n",
    "# Portanto, vamos criar duas listas com o objetivo de separar\n",
    "# as colunas que conseguiram ser plotadas por histograma e as\n",
    "# que falharam. Para isso, utilizaremos um laço de exceção\n",
    "# que será responsável por separar as colunas em suas respectivas\n",
    "# listas\n",
    "\n",
    "list_good_columns = []\n",
    "list_bad_columns = []\n",
    "i = 1\n",
    "\n",
    "# Iterando por todas as colunas \n",
    "for column in df.columns:\n",
    "    try:\n",
    "        median_existing = existing[column].describe().T[5]\n",
    "        median_attrited = attrited[column].describe().T[5]\n",
    "        print(f\"Analisando coluna: {column}\")\n",
    "        print(f\"mediana dos clientes: {median_existing}\")\n",
    "        print(f\"mediana dos ex-clientes: {median_attrited}\")\n",
    "        list_good_columns.append(column)\n",
    "        \n",
    "        plt.style.use(\"bmh\")\n",
    "        plt.hist(existing[column], edgecolor=\"black\", bins=20,\n",
    "         label=\"existing customers\")\n",
    "        plt.hist(attrited[column], edgecolor=\"black\", bins=20,\n",
    "                label=\"attrited customers\")\n",
    "        plt.axvline(x = median_existing, color=\"orange\",\n",
    "                    label=f\"median_existing: {median_existing}\", ls='--')\n",
    "        plt.axvline(x = median_attrited, color=\"black\",\n",
    "                    label=f\"median_attrited: {median_attrited}\", ls='--')\n",
    "        plt.xlabel(\"valores\")\n",
    "        plt.ylabel(\"frequência\")\n",
    "        plt.title(f\"Gráfico {i} - Histograma para coluna {column}\")\n",
    "        plt.grid(alpha=0.35, color=\"black\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        i += 1\n",
    "    except:\n",
    "       # print(f\"coluna {column} não possui valores numéricos\")\n",
    "        list_bad_columns.append(column)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dessa maneira, poderemos ver, gráfico a gráfico, quais dos atributos numéricos há uma disparidade de ocorrências no universo de clientes e de ex-clientes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminando atributos da análise\n",
    "\n",
    "Seguindo a estratégia de análise já definida, podemos excluir como fatores relevantes para a virada de chave do cliente os atributos de idade `Customer_Age`, número de dependentes `Dependent_count`, tempo como cliente `Months_on_book`, Linha de crédito disponível `Avg_Open_To_Buy`, mudança da quantidade de valores transacionados entre o último e o primeiro trimestres do ano `Total_Amt_Chng_Q4_Q1`, mudança na quantidade de transações `Total_CT_Chng_Q4_Q1`.\n",
    "\n",
    "Optamos por essa decisão pois não há mudança radical de mediana entre o universo de clientes e ex-clientes no que tange esses atributos. A proximidade das medianas parece nos indicar que não seja um fator relevante para predição da mudança de comportamento do cliente. Incentivar uma postura proativa nesses casos pode significar dispêndio de energia em clientes que não correm o risco de abandonar o banco."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecionando histogramas que não ficaram bons\n",
    "\n",
    "Como utilizamos um método de força bruta, já sabíamos que alguns não ficariam bons. As colunas `Total_Relationship_Count`, `Months_Inactive_12_mon` e `Contacts_Count_12_mon` serão armazenadas numa variável lista com o objetivo de retornarmos a elas futuramente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_histograms = [\"Dependent_count\", \"Total_Relationship_Count\",\n",
    "                  \"Months_Inactive_12_mon\", \"Contacts_Count_12_mon\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise dos histogramas bons\n",
    "\n",
    "Os histogramas são boas visualizações para dados numéricos e contínuos. Nesse sentido, os gráficos das colunas que representam límite de crédito `Credit_Limit`, total de quantidade transacionada nos últimos 12 meses `Total_Trans_Amt`, total de transações nos últimos 12 meses `Total_Trans_Ct` e saldo rotativo total `Total_Revolving_Bal` nos permite tirar conclusões ou, no mínimo, intuições sobre o que pode indicar/prever a mudança de comportamento do cliente."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Limite de Crédito"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embora a distribuição de variáveis seja similar, a disparidade de medianas pode indicar que clientes com maior limite de crédito tendem a permanecer no banco. Entretanto, não há valor preditivo a olho nu a partir dessa variável. Ela pode ser útil após um tratamento em modelo de aprendizado de máquina."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saldo de Crédito Rotativo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O saldo de crédito rotativo parece ser um bom indicador para a mudança de comportamento do cliente para se tornar ex-cliente. Como mostra a mediana, há uma concentração expressiva de ex-clientes que zeraram o balanço do crédito rotativo. A ação de zerar o balanço de crédito rotativo deve ligar uma luz amarela para a gerência do banco, que deve ter estratégias desenvolvidas para agir proativamente."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Valor total utilizado em transferências"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A distância entre as medianas mostra que ex-clientes tendem a transacionar menores quantias quando interagem com os serviços do banco."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quantidade total de transações"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da mesma forma que no dado anterior, os ex-clientes tendem a realizar um menor número de transações por meio do banco e seu cartão de crédito. Dessa maneira, a gerência deve se atentar a esse dado para desenvolver estratégias proativas a contorná-lo."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replotando os histogramas que não ficaram bons como gráfico de pizza"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos replotar os histogramas que não ficaram legais, em razão da natureza _discreta_ dos dados, em gráficos de pizza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recuperando a variável\n",
    "bad_histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continuando a numeração de onde paramos\n",
    "i = 15\n",
    "for column in bad_histograms:\n",
    "    print(f\"Gráfico {i} - Analisando a coluna: {column}\")\n",
    "    counts_existing = existing[column].value_counts()\n",
    "    counts_attrited = attrited[column].value_counts()\n",
    "#    print(counts_existing)\n",
    " #   print(counts_attrited)\n",
    "    plt.pie(counts_existing.values, labels=counts_existing.index, autopct='%1.1f%%')\n",
    "    plt.axis('equal')\n",
    "    plt.title(f\"Gráfico {i}a - Existing {column}\")\n",
    "    plt.show()\n",
    "    plt.pie(counts_attrited.values, labels=counts_attrited.index, autopct='%1.1f%%')\n",
    "    plt.axis('equal')\n",
    "    plt.title(f\"Gráfico {i}b - Attrited {column}\")\n",
    "    plt.show()\n",
    "    i += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Excluindo as variáveis da análise\n",
    "\n",
    "A coluna que mostra a contagem de dependentes `Dependent_count` indica que esse dado não há relevância para a mudança do comportamento dos clientes. O mesmo podemos falar para a coluna `Total_Relationship_Count`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Meses de inatividade"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por outro lado, há uma mudança de comportamento das variáveis nas demais colunas. \n",
    "\n",
    "A dupla de gráficos 16 indica que quanto mais meses o cliente se mostra inativo nos últimos 12 meses, maior a chance dele se tornar ex-cliente. Dessa maneira, a visualização dos dados indica que a gerência deve tomar medidas estratégicas a partir do segundo mês de inatividade, impedindo que se chege ao terceiro mês.\n",
    "\n",
    "Na ocasião do cliente se mostrar inativo num terceiro mês, nem tudo está perdido. O banco ainda terá cartas para jogar e tentar manter o cliente como interessado nos serviços. Porém, a chance a partir do terceiro mês de inatividade é consideravelmente maior."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quantidade de contatos\n",
    "\n",
    "O dataset não especifica se a coluna se refere a contatos feitos pelo banco com o cliente, se contatos feito pelo cliente com o banco, ou uma mistura de ambos. De qualquer forma, é nítido que deve haver uma mudança na forma que o banco se comunica com seus clientes por meios internos, haja vista que, quanto maior o número de contatos, maior a chance do cliente se tornar ex-cliente."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Analisando os atributos categóricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recuperando a variável que armazena as colunas que contém valores categóricos\n",
    "\n",
    "list_bad_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conhecendo as variáveis de cada atributo\n",
    "\n",
    "df[\"Education_Level\"].unique()\n",
    "\n",
    "list_bad_columns \n",
    "\n",
    "for i in list_bad_columns:\n",
    "    print(f\"Coluna: {i}\")\n",
    "    print(df[f\"{i}\"].unique())\n",
    "    print(\"\\n\")\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que não faz sentido analisar a coluna `Attrition_Flag` pois ela é a coluna que utilizamos para separar nossos dados. Por isso, vamos excluí-la da lista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_bad_columns = [\n",
    " 'Gender',\n",
    " 'Education_Level',\n",
    " 'Marital_Status',\n",
    " 'Income_Category',\n",
    " 'Card_Category']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos realizar método similar, para evitar tarefas repetitivas, utilizando o gráfico de pizza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 19\n",
    "for column in list_bad_columns:\n",
    "    print(f\"Gráfico {i} - Analisando a coluna: {column}\")\n",
    "    counts_existing = existing[column].value_counts()\n",
    "    counts_attrited = attrited[column].value_counts()\n",
    "#    print(counts_existing)\n",
    " #   print(counts_attrited)\n",
    "    plt.pie(counts_existing.values, labels=counts_existing.index, autopct='%1.1f%%')\n",
    "    plt.axis('equal')\n",
    "    plt.title(f\"Gráfico {i}a - Existing {column}\")\n",
    "    plt.show()\n",
    "    plt.pie(counts_attrited.values, labels=counts_attrited.index, autopct='%1.1f%%')\n",
    "    plt.axis('equal')\n",
    "    plt.title(f\"Gráfico {i}b - Attrited {column}\")\n",
    "    plt.show()\n",
    "    i += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avaliando as visualizações, nenhum dos atributos parece ter influência ou valor preditivo para avaliar se um cliente se tornará ex-cliente nos próximos meses ou não. Nesse sentido, passaremos reto para o restante da análise"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Pré-Processamento e matriz de correlação"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma das características desse conjunto de dados é possuir tanto colunas numéricas como colunas textuais. Na ótica da matriz de correlação, precisamos apenas de valores numéricos para sua visualização. Inicialmente, podemos excluir as colunas textuais para uma primeira visualização."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "sn.heatmap(df.corr(), annot=True)\n",
    "plt.show()\n",
    "\n",
    "# O FutureWarning acontece pois o método de separação de variáveis numéricas\n",
    "# das não-numéricas está deprecado. Devido a isso, ele sugere que façamos um \n",
    "# filtro previamente para que não haja problemas de compatibilidade com versões\n",
    "# futuras que não conseguirão mais fazer essa separação automaticamente.\n",
    "# No momento atual, podemos continuar fazendo desse jeito."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apesar dessa matriz de correlação inicial apresentar as relações entre as variáveis numéricas, várias colunas foram deixadas de fora por serem valores textuais (`string`), inclusive a coluna de interesse `Attrition_Flag`. Para resolver esse problema, usaremos os chamados _encoders_: classes responsáveis por fazer mapeamentos de categorias em valores numéricos, mantendo suas relações. Inicialmente, adicionaremos a coluna _Attrition Flag_ utilizando o `LabelEncoder`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enc = df.copy()\n",
    "# Garantindo que não vamos alterar as informações no dataframe original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(df_enc['Attrition_Flag'])\n",
    "df_enc['Attrition_Flag'] = label_encoder.transform(df_enc['Attrition_Flag'])\n",
    "print(f\"Classes: {label_encoder.classes_}\")\n",
    "df_enc.head()\n",
    "\n",
    "# 1 = Existing customer\n",
    "# 0 = Attrited customer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos reprocessar a matriz de correlação com a coluna de interesse transformada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "sn.heatmap(df_enc.corr(), annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na matriz de correlação, podemos identificar que algumas variáveis possuem correlação positiva (acima de 0) com o atributo `Attrition_Flag`. Arbitrariamente, selecionaremos os atributos com correlação acima de 0.2. São eles: saldo da conta de crédito rotativo `Total_Revolving_Bal`, quantidade de transações nos últimos 12 meses `Total_Trans_Ct` e a maior, modificação da quantidade de transações de um ano para o outro (do quarto para o primeiro trimestre)`Total_Ct_Chang_Q4_Q1`. Essas são as correlações mais fortes no universo de dados presentes.\n",
    "\n",
    "É interessante que a análise de correlação retoma atributos que haviam anteriormente excluídos pela análise a olho nu, como `Total_Ct_Chang_Q4_Q1`.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo, faremos um _encoding_ das demais colunas não-numéricas.\n",
    "\n",
    "As colunas a seguir possuem mais de uma categoria, e essas categorias não possuem ordem hierárquica entre si. Por causa disso, a técnica de _encoding_ utilizada anteriormente não funciona. Utilizaremos o `OneHotEncoding` para transformar essa variáveis.\n",
    "\n",
    "Obs: Para facilitar a transformação, já que estamos trabalhando com um dataframe, utilizaremos o `LabelBinarizer`, uma implementação da técnica de `OneHotEncoding` mais amigável para dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_cols = [\"Education_Level\",\n",
    "             \"Marital_Status\",\n",
    "             \"Income_Category\",\n",
    "             \"Card_Category\"]\n",
    "\n",
    "# Separando as colunas\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "list_dfs = [] # Criando uma lista para armazenar os dfs encodados\n",
    "\n",
    "for column in string_cols:\n",
    "  # Iterando pelas colunas, faremos uma instância do LabelBinarizer\n",
    "  # para cada uma, aplicando na coluna e retornando a variável df_out.\n",
    "  enc = LabelBinarizer()\n",
    "  enc.fit(df[column])\n",
    "  transformed = enc.transform(df[column])\n",
    "  df_out = pd.DataFrame(transformed)\n",
    "\n",
    "  # a iteração a seguir será feita com objetivo de renomear o dataframe gerado\n",
    "  # com os nomes das colunas originais para melhor entendimento\n",
    "  # do usuário que for manipular o dataframe\n",
    "  i = 0\n",
    "  dict_names = {}\n",
    "  classes = list(enc.classes_)\n",
    "  for name in classes:\n",
    "      dict_names[i] = f\"{column}{name}\"\n",
    "      i += 1\n",
    "\n",
    "  # Renomeando as colunas e montando a lista de dataframes\n",
    "  df_out.rename(columns=dict_names, inplace=True)\n",
    "  list_dfs.append(df_out)\n",
    "\n",
    "# Concatenando os dataframes no original.\n",
    "list_dfs.append(df_enc)\n",
    "df_full_enc = pd.concat(list_dfs, axis=1)\n",
    "df_full_enc.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que agora todas as variáveis são numéricas, e novas colunas foram adicionadas com os dados _encodados_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_enc.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A transformação das variáveis em números possibilita a visualização de estatísticas descritivas onde antes eram apenas `strings`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_enc.describe().T"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim, _plotaremos_ a matriz de correlação final com todos os dados encodados. Essa matriz não apresenta uma leitura visual capaz de tirar conclusões a olhos nus, mas está exposta para fins demonstrativos, já que a anterior já correlaciona a maioria das variáveis importantes para nosso objetivo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(30,25))\n",
    "sn.heatmap(df_full_enc.corr(), annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Daqui em diante, o dataframe está pronto para modelagem."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Conclusão\n",
    "\n",
    "Após a análise dos dados e das visualizações produzidas, percebemos que é possível identificar elementos que possam identificar uma mudança de comportamento de um cliente em vias de se tornar ex-cliente. Técnicas de aprendizado de máquina podem aprofundar ainda mais essa análise, retornando novas métricas e indicadores preditivos mais acurados."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entretanto, enquanto tais modelos não são desenvolvidos para o caso em análise, podemos indicar as seguintes medidas para a gerência do banco:\n",
    "\n",
    "- **Focar nos grupos de menor renda** do universo observável: embora o poder de compra seja individualmente menor, a maioria da clientela do banco possui rendimentos inferiores a 60 mil dólares, o que equivale a 52,6%. Por isso, estratégias focalizadas nesse grupo podem fortalecer a base de clientes.\n",
    "\n",
    "- **Buscar estratégias de comunicação para grupos de maior renda**: Quanto mais diversificada for a base de renda dos clientes, mais blindado o banco será aos padrões de comportamento de um determinado setor social.\n",
    "\n",
    "- **Agir proativamente quando a atividade estiver baixa**: Existe uma maior incidência de níveis de atividades reduzidos no grupo de ex-clientes analisados, de maneira que é inteligente focalizar ações proativas para retenção em grupos de clientes em que a redução da atividade nos últimos 12 meses  seja visível.\n",
    "\n",
    "- **Fortalecer a integração de produtos**: Vimos que quanto menos produtos os clientes utilizam, mais eles tendem a abandonar os serviços do banco. Desas maneira, quanto mais integrados forem os produtos, mais os clientes se envolverão no ecossistema de serviços do banco e tenderão a permanecer.\n",
    "\n",
    "- **Crie formas de incentivar o uso do cartão de crédito pelos clientes**: Uma forma de recompensa ou de pontuação, por exemplo, pode ser a diferença significativa entre um cliente que abandona o banco e um cliente que permanece cliente.\n",
    "\n",
    "- **Desenvolvimento de melhor estratégia de comunicação**: Vimos que há uma maior incidência de contatos entre o banco e o cliente no universo analisável dos ex-clientes. Podemos inferir que a estratégia de comunicação do banco não está sendo eficiente para retê-los. É interessante que se investigue os problemas e a comunicação seja melhorada."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
